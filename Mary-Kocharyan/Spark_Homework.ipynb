{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // Or use any other 2.x version here\n",
       "// import $ivy.`sh.almond::almond-spark:_` // Added automatically on importing Spark\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.SparkContext\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.SparkConf\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.3` // Or use any other 2.x version here\n",
    "// import $ivy.`sh.almond::almond-spark:_` // Added automatically on importing Spark\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.Column\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types.{DataType, DateType, TimestampType}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Column\n",
    "import org.apache.spark.sql.types.{DataType, DateType, TimestampType}\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@4eab7bc4\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msc\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var spark = SparkSession\n",
    ".builder()\n",
    ".appName(\"Java Spark SQL Homework\")\n",
    ".config(\"spark.master\", \"local\")\n",
    ".getOrCreate();\n",
    "def sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.sql.Date\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.sql.Date\n",
    "import org.apache.spark.sql.expressions.Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[39m: \u001b[32mDataFrame\u001b[39m = [device_id: string, country_code: string ... 12 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var data = spark.read.\n",
    "option(\"header\", true).\n",
    "option(\"inferSchema\",true).\n",
    "csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [device_id: string, country_code: string ... 13 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = data.withColumn(\"date\", data(\"timestamp\").cast(DateType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mretention\u001b[39m: \u001b[32mDataFrame\u001b[39m = [date: date, device_id: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var retention = df.select(\"date\",\"device_id\")//I have selected the columns I need for the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mnewframe\u001b[39m: \u001b[32mDataFrame\u001b[39m = [date_after: date, device_id_after: string ... 1 more field]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//I am going to join my data with itself, so I have copied the data and renamed its columns.\n",
    "//I have also added a new column where the number of days is substracted from the \"date\" column(in our example 1 or 7 days).\n",
    "val newframe = retention.withColumnRenamed(\"date\",\"date_after\").\n",
    "withColumnRenamed(\"device_id\",\"device_id_after\").\n",
    "withColumn(\"date_back\",date_sub(col(\"date_after\"),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mjoined\u001b[39m: \u001b[32mDataFrame\u001b[39m = [date: date, device_id: string ... 3 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Here I have joined the data so that the device_id is the same and the date is equal to my new column with substracted date\n",
    "var joined = retention.join(newframe,\n",
    "        retention(\"device_id\") === newframe(\"device_id_after\")\n",
    "        && retention(\"date\") === newframe(\"date_back\"),\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mactive\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [date: date, active: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//this shows the number of active users each day\n",
    "var active = (joined.groupBy(\"date\").agg(countDistinct(\"device_id\").as(\"active\")).orderBy(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mreturned\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [date: date, returned: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//this shows the number of returned users\n",
    "var returned = (joined.groupBy(\"date\").agg(countDistinct(\"device_id_after\").as(\"returned\")).orderBy(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mret\u001b[39m: \u001b[32mDataFrame\u001b[39m = [date: date, active: bigint ... 2 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//joining those two DFs by \"date\" and calculating the percent, we get the retention table for each day\n",
    "var ret = active.join (returned,Seq(\"date\"),\"left\").orderBy(\"date\").\n",
    "withColumn(\"percent\",round(col(\"returned\")/col(\"active\")*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------+-------+\n",
      "|      date|active|returned|percent|\n",
      "+----------+------+--------+-------+\n",
      "|2018-02-02|    98|      35|  35.71|\n",
      "|2018-02-03|    35|      21|   60.0|\n",
      "|2018-02-04|    39|      24|  61.54|\n",
      "|2018-02-05|    43|      24|  55.81|\n",
      "|2018-02-06|    35|      23|  65.71|\n",
      "|2018-02-07|    34|      20|  58.82|\n",
      "|2018-02-08|    37|      15|  40.54|\n",
      "|2018-02-09|    28|      15|  53.57|\n",
      "|2018-02-10|    32|      17|  53.13|\n",
      "|2018-02-11|    26|      19|  73.08|\n",
      "|2018-02-12|    34|      23|  67.65|\n",
      "|2018-02-13|    29|      22|  75.86|\n",
      "|2018-02-14|    46|      19|   41.3|\n",
      "|2018-02-15|    28|      15|  53.57|\n",
      "|2018-02-16|    31|      12|  38.71|\n",
      "|2018-02-17|    19|       0|    0.0|\n",
      "+----------+------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ret.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         retention|\n",
      "+------------------+\n",
      "|55.666666666666664|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//To calculate the average retention rate we should drop the last 1 day, because that's the last day of our frame, and the \n",
    "//retention rate is 0.(when calculating the D7 retention, we should drop last 7 days)\n",
    "var av_retention = ret.filter(col(\"date\") =!= \"2018-02-17\").agg(avg(\"percent\").as(\"retention\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mnewframe\u001b[39m: \u001b[32mDataFrame\u001b[39m = [date_after: date, device_id_after: string ... 1 more field]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//To calculate the D7 retention we can repeat the same only changing the number of days substracted from the date\n",
    "val newframe = retention.withColumnRenamed(\"date\",\"date_after\").\n",
    "withColumnRenamed(\"device_id\",\"device_id_after\").\n",
    "withColumn(\"date_back\",date_sub(col(\"date_after\"),7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mjoined\u001b[39m: \u001b[32mDataFrame\u001b[39m = [date: date, device_id: string ... 3 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var joined = retention.join(newframe,\n",
    "        retention(\"device_id\") === newframe(\"device_id_after\")\n",
    "        && retention(\"date\") === newframe(\"date_back\"),\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mactive\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [date: date, active: bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var active = (joined.groupBy(\"date\").agg(countDistinct(\"device_id\").as(\"active\")).orderBy(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mreturned\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [date: date, returned: bigint]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var returned = (joined.groupBy(\"date\").agg(countDistinct(\"device_id_after\").as(\"returned\")).orderBy(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mret\u001b[39m: \u001b[32mDataFrame\u001b[39m = [date: date, active: bigint ... 2 more fields]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var ret = active.join (returned,Seq(\"date\"),\"left\").orderBy(\"date\").\n",
    "withColumn(\"percent\",round(col(\"returned\")/col(\"active\")*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------+-------+\n",
      "|      date|active|returned|percent|\n",
      "+----------+------+--------+-------+\n",
      "|2018-02-02|    98|      28|  28.57|\n",
      "|2018-02-03|    35|      13|  37.14|\n",
      "|2018-02-04|    39|      18|  46.15|\n",
      "|2018-02-05|    43|      23|  53.49|\n",
      "|2018-02-06|    35|      12|  34.29|\n",
      "|2018-02-07|    34|      20|  58.82|\n",
      "|2018-02-08|    37|      14|  37.84|\n",
      "|2018-02-09|    28|      14|   50.0|\n",
      "|2018-02-10|    32|       7|  21.88|\n",
      "|2018-02-11|    26|       0|    0.0|\n",
      "|2018-02-12|    34|       0|    0.0|\n",
      "|2018-02-13|    29|       0|    0.0|\n",
      "|2018-02-14|    46|       0|    0.0|\n",
      "|2018-02-15|    28|       0|    0.0|\n",
      "|2018-02-16|    31|       0|    0.0|\n",
      "|2018-02-17|    19|       0|    0.0|\n",
      "+----------+------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ret.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(percent)|\n",
      "+------------------+\n",
      "|40.908888888888896|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var av_retention = ret.filter(col(\"date\") < \"2018-02-11\").agg(avg(\"percent\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mretention\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//The automation of this method can look like this.\n",
    "//The function takes data and the number of days retention should be calculated for\n",
    "def retention(data:DataFrame,days:Int):Unit ={\n",
    "  var df = data.withColumn(\"date\", data(\"timestamp\").cast(DateType))\n",
    "  var retention = df.select(\"date\",\"device_id\")\n",
    "  val newframe = retention.withColumnRenamed(\"date\",\"date_after\").\n",
    "  withColumnRenamed(\"device_id\",\"device_id_after\").\n",
    "  withColumn(\"date_back\",date_sub(col(\"date_after\"),days))\n",
    "  var joined = retention.join(newframe,\n",
    "        retention(\"device_id\") === newframe(\"device_id_after\")\n",
    "        && retention(\"date\") === newframe(\"date_back\"),\"left\")\n",
    "  var ret = (joined.groupBy(\"date\").agg(countDistinct(\"device_id\").as(\"active\")).orderBy(\"date\")).\n",
    "  join ((joined.groupBy(\"date\").agg(countDistinct(\"device_id_after\").as(\"returned\")).orderBy(\"date\")),Seq(\"date\"),\"left\").\n",
    "  orderBy(\"date\").\n",
    "  withColumn(\"percent\",round(col(\"returned\")/col(\"active\")*100,2))\n",
    "  val window = Window.orderBy(df(\"date\").desc)\n",
    "  var retent = ret.withColumn(\"rank\", rank().over(window)).\n",
    "  filter(col(\"rank\") > days). \n",
    "  drop(\"rank\").agg(round(avg(\"percent\"),2).as(\"retention\")).show\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|retention|\n",
      "+---------+\n",
      "|    55.67|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retention(data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|retention|\n",
      "+---------+\n",
      "|    40.91|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retention(data,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "//here can be used the function for the previos example, only adding the column we want as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mretentionEvent\u001b[39m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retentionEvent(data:DataFrame,days:Int,column:String):Unit ={\n",
    "  var df = data.withColumn(\"date\", data(\"timestamp\").cast(DateType))\n",
    "  var retentt = df.select(\"date\",\"device_id\",\"event_type\")\n",
    "  var retention = retentt.filter(col(\"event_type\") === column)\n",
    "  var newframe = retention.withColumnRenamed(\"date\",\"date_after\").\n",
    "  withColumnRenamed(\"device_id\",\"device_id_after\").\n",
    "  withColumnRenamed(\"event_type\",\"event\").\n",
    "  withColumn(\"date_back\",date_sub(col(\"date_after\"),days))\n",
    "  var joined = retention.join(newframe,\n",
    "        retention(\"device_id\") === newframe(\"device_id_after\")\n",
    "        && retention(\"date\") === newframe(\"date_back\"),\"left\")\n",
    "  var ret = (joined.groupBy(\"date\").agg(countDistinct(\"device_id\").as(\"active\")).orderBy(\"date\")).\n",
    "  join ((joined.groupBy(\"date\").agg(countDistinct(\"device_id_after\").as(\"returned\")).orderBy(\"date\")),Seq(\"date\"),\"left\").\n",
    "  orderBy(\"date\").\n",
    "  withColumn(\"percent\",round(col(\"returned\")/col(\"active\")*100,2))\n",
    "  val window = Window.orderBy(df(\"date\").desc)\n",
    "  var retent = ret.withColumn(\"rank\", rank().over(window)).\n",
    "  filter(col(\"rank\") > days). \n",
    "  drop(\"rank\").agg(round(avg(\"percent\"),2).as(\"retention\")).show\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|retention|\n",
      "+---------+\n",
      "|    24.64|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retentionEvent(data,1,\"edit_text_apply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|retention|\n",
      "+---------+\n",
      "|    35.13|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retentionEvent(data,1,\"effect_apply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|retention|\n",
      "+---------+\n",
      "|    41.59|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retentionEvent(data,1,\"edit_item_open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|retention|\n",
      "+---------+\n",
      "|     7.69|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retentionEvent(data,1,\"edit_sticker_apply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlike\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [device_id: string, country_code: string ... 13 more fields]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var like = df.filter(col(\"event_type\") === \"photo_like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------------+\n",
      "|      date|count(DISTINCT device_id)|\n",
      "+----------+-------------------------+\n",
      "|2018-02-03|                        1|\n",
      "|2018-02-08|                        1|\n",
      "+----------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "like.groupBy(\"date\").agg(countDistinct(\"device_id\")).orderBy(\"date\").show\n",
    "//as our data is not large, there are only two users who did photo_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mnext\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [device_id: string, country_code: string ... 14 more fields]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var next = df.withColumn(\"next_event\",lead(\"event_type\",1)over Window.partitionBy(\"device_id\").orderBy(\"timestamp\")).\n",
    "filter(col(\"event_type\") === \"effect_try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mef_ap\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [device_id: string, country_code: string ... 14 more fields]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var ef_ap = next.filter(col(\"next_event\") === \"effect_apply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mrate\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m71.42857142857143\u001b[39m"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var rate = ef_ap.agg(countDistinct(\"device_id\")).take(1)(0)(0).toString.toDouble/\n",
    "            next.agg(countDistinct(\"device_id\")).take(1)(0)(0).toString.toInt*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mconversion\u001b[39m"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//automation\n",
    "def conversion(data:DataFrame,column1:String,column2:String):Unit ={\n",
    "  var df = data.withColumn(\"date\", data(\"timestamp\").cast(DateType))\n",
    "  var next = df.withColumn(\"next_event\",lead(\"event_type\",1)over Window.partitionBy(\"device_id\").orderBy(\"timestamp\")).\n",
    "  filter(col(\"event_type\") === column1)\n",
    "  var ef_ap = next.filter(col(\"next_event\") === column2)\n",
    "  println(ef_ap.agg(countDistinct(\"device_id\")).take(1)(0)(0).toString.toDouble/\n",
    "            next.agg(countDistinct(\"device_id\")).take(1)(0)(0).toString.toInt*100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.42857142857143\n"
     ]
    }
   ],
   "source": [
    "conversion(data,\"effect_try\",\"effect_apply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36meff_app\u001b[39m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eff_app = df.filter(col(\"event_type\") === \"effect_apply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mef\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [date: date, users: bigint]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var ef = eff_app.groupBy(\"date\").agg(countDistinct(\"device_id\").as (\"users\")).orderBy(col(\"users\").desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|users|\n",
      "+----------+-----+\n",
      "|2018-02-02|   21|\n",
      "|2018-02-12|   13|\n",
      "|2018-02-04|   12|\n",
      "|2018-02-11|   10|\n",
      "|2018-02-15|   10|\n",
      "|2018-02-03|    9|\n",
      "|2018-02-10|    9|\n",
      "|2018-02-05|    8|\n",
      "|2018-02-08|    8|\n",
      "|2018-02-14|    8|\n",
      "|2018-02-06|    8|\n",
      "|2018-02-13|    7|\n",
      "|2018-02-09|    6|\n",
      "|2018-02-17|    5|\n",
      "|2018-02-16|    5|\n",
      "|2018-02-07|    5|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ef.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|            users|\n",
      "+-------+-----------------+\n",
      "|  count|               16|\n",
      "|   mean|              9.0|\n",
      "| stddev|3.966526608171604|\n",
      "|    min|                5|\n",
      "|    max|               21|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ef.describe().show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|      date|users|percentile|\n",
      "+----------+-----+----------+\n",
      "|2018-02-10|    9|       0.6|\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ef.withColumn(\"percentile\", percent_rank() over Window.orderBy(\"users\")).\n",
    "    filter(col(\"percentile\")>= 0.5).\n",
    "    limit(1).show\n",
    "//we can see that 0.5 percentile which is the median is equal to the mean (we can assume that we don't have outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mq1\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m7\u001b[39m\n",
       "\u001b[36mq3\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m12\u001b[39m\n",
       "\u001b[36minterquantile\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m5\u001b[39m"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//to find out whether we have outliers, I will use the outlier formula. \n",
    "//for that I should calculate the Q1,Q3,Interquantile range, and later see if my data has outliers\n",
    "var q1 = ef.withColumn(\"percentile\", percent_rank() over Window.orderBy(\"users\")).\n",
    "    filter(col(\"percentile\")>= 0.25).\n",
    "    limit(1).take(1)(0)(1).toString.toInt\n",
    "var q3 = ef.withColumn(\"percentile\", percent_rank() over Window.orderBy(\"users\")).\n",
    "    filter(col(\"percentile\")>= 0.75).\n",
    "    limit(1).take(1)(0)(1).toString.toInt\n",
    "var interquantile = q3 - q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlower_outlier\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m-8\u001b[39m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var lower_outlier = q1 - (3*interquantile)// as we don't have a number smaller than -8, we have no lower ouliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mupper_outlier\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m27\u001b[39m"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var upper_outlier =  q3 + (3*interquantile)//as we don't have a number greater than 27, we have no upper outliers as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+-----+-------+\n",
      "|events                                                                                         |users|percent|\n",
      "+-----------------------------------------------------------------------------------------------+-----+-------+\n",
      "|effect_try,effect_try,effect_try,effect_try,effect_try                                         |42   |42.86  |\n",
      "|native_ad_response,native_ad_waterfall,native_ad_request,native_ad_response,native_ad_waterfall|41   |41.84  |\n",
      "|shop_response,shop_request,shop_response,shop_request,shop_response                            |38   |38.78  |\n",
      "|native_ad_response,native_ad_waterfall,native_ad_response,native_ad_waterfall,native_ad_request|37   |37.76  |\n",
      "|shop_request,shop_response,shop_request,shop_response,shop_request                             |35   |35.71  |\n",
      "+-----------------------------------------------------------------------------------------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mwindow\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@2491e84"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var window = Window.partitionBy(\"device_id\").orderBy(\"timestamp\")\n",
    "df.\n",
    "withColumn(\"event_2\", lead(\"event_type\", 1) over window).\n",
    "withColumn(\"event_3\", lead(\"event_type\", 2) over window).\n",
    "withColumn(\"event_4\", lead(\"event_type\", 3) over window).\n",
    "withColumn(\"event_5\", lead(\"event_type\", 4) over window).\n",
    "withColumn(\"events\",concat(col(\"event_type\"),lit(\",\"),col(\"event_2\"),lit(\",\"),col(\"event_3\"),lit(\",\"),col(\"event_4\"),lit(\",\"),col(\"event_5\"))).\n",
    "select(\"device_id\",\"events\").\n",
    "groupBy(\"events\").\n",
    "agg(countDistinct(\"device_id\").as(\"users\")).\n",
    "orderBy(col(\"users\").desc).na.drop.\n",
    "withColumn(\"percent\",round(col(\"users\") / df.agg(countDistinct(\"device_id\")).take(1)(0)(0).toString.toInt*100,2))\n",
    ".show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*To describe one session of the user I think we should pay attantion:\n",
    "1.to the number of events done during the session,\n",
    "2.to the frequencies of each event, so we can calculate the event user does the most or the least,\n",
    "3.to the firts events done, which I think indicates what is the main reason user opened the app,\n",
    "4.if after trying some tool user applied it (e.g. effect_try,effect_apply)\n",
    "5.if after editing the photo user saved it in the phone,uploaded it or just closed\n",
    "the app, without saving the changes done.*/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.11)",
   "language": "scala",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
