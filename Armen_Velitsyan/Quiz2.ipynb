{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T13:09:05.104145Z",
     "start_time": "2019-12-02T13:09:04.101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // Or use any other 2.x version here\n",
       "// import $ivy.`sh.almond::almond-spark:_` // Added automatically on importing Spark\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.SparkContext\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.SparkConf\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.3` // Or use any other 2.x version here\n",
    "// import $ivy.`sh.almond::almond-spark:_` // Added automatically on importing Spark\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T13:53:00.999636Z",
     "start_time": "2019-12-02T13:53:00.832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.Column\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types.{DataType, DateType, TimestampType}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Column\n",
    "import org.apache.spark.sql.types.{DataType, DateType, TimestampType}\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T13:09:11.556699Z",
     "start_time": "2019-12-02T13:09:10.944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@335ff79e\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msc\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var spark = SparkSession\n",
    ".builder()\n",
    ".appName(\"Java Spark SQL basic example\")\n",
    ".config(\"spark.master\", \"local\")\n",
    ".getOrCreate();\n",
    "\n",
    "def sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:17:55.228522Z",
     "start_time": "2019-12-02T14:17:54.689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mframe\u001b[39m: \u001b[32mDataFrame\u001b[39m = [country_code: string, device_id: string ... 12 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val frame = spark.read.option(\"header\", true).option(\"delimiter\", \",\").option(\"inferSchema\",true).csv(\"homeworkfile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T13:29:09.892869Z",
     "start_time": "2019-12-02T13:29:09.775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.joda.time.format.DateTimeFormat\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.joda.time.{DateTime, Days}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.joda.time.format.DateTimeFormat\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.Properties\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.DataFrame\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{DataFrame, SQLContext}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.{SparkConf, SparkContext}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.joda.time.{DateTime, Days}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{DataFrame, SparkSession}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SaveMode._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.SparkConf\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.json4s._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.json4s.jackson.JsonMethods._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.joda.time.format.DateTimeFormat\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.joda.time.{DateTime, Days}\n",
       "\u001b[39m\n",
       "\u001b[36mformatter\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mjoda\u001b[39m.\u001b[32mtime\u001b[39m.\u001b[32mformat\u001b[39m.\u001b[32mDateTimeFormatter\u001b[39m = org.joda.time.format.DateTimeFormatter@457ae07c\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Try\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.sql.{Connection, DriverManager, ResultSet}\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.joda.time.format.DateTimeFormat\n",
    "import org.joda.time.{DateTime, Days}\n",
    "import org.joda.time.format.DateTimeFormat\n",
    "import java.util.Properties\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.{DataFrame, SQLContext}\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.joda.time.{DateTime, Days}\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import org.apache.spark.sql.SaveMode._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.json4s._\n",
    "import org.json4s.jackson.JsonMethods._\n",
    "import org.joda.time.format.DateTimeFormat\n",
    "import org.joda.time.{DateTime, Days}\n",
    "val formatter = DateTimeFormat.forPattern(\"yyyy-MM-dd\")\n",
    "import scala.util.Try\n",
    "import java.sql.{Connection, DriverManager, ResultSet}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- device_id: string (nullable = true)\n",
      " |-- advertising_id: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- platform: string (nullable = true)\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timezone: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- app: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- v: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frame.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+\n",
      "|Date_of_event|Number of active users|\n",
      "+-------------+----------------------+\n",
      "|   2018-02-02|                 25455|\n",
      "|   2018-02-03|                 26682|\n",
      "|   2018-02-04|                 28148|\n",
      "|   2018-02-05|                 25876|\n",
      "|   2018-02-06|                 25070|\n",
      "|   2018-02-07|                 24123|\n",
      "|   2018-02-08|                 25137|\n",
      "|   2018-02-09|                 25859|\n",
      "|   2018-02-10|                 26963|\n",
      "|   2018-02-11|                 28552|\n",
      "|   2018-02-12|                 30262|\n",
      "|   2018-02-13|                 26881|\n",
      "|   2018-02-14|                 26451|\n",
      "|   2018-02-15|                 25735|\n",
      "|   2018-02-16|                 26747|\n",
      "|   2018-02-17|                 26456|\n",
      "|   2018-02-18|                 27925|\n",
      "|   2018-02-19|                 25989|\n",
      "|   2018-02-20|                 25734|\n",
      "|   2018-02-21|                 26540|\n",
      "|   2018-02-22|                 26768|\n",
      "|   2018-02-23|                 27600|\n",
      "|   2018-02-24|                 28744|\n",
      "|   2018-02-25|                 29186|\n",
      "|   2018-02-26|                 26895|\n",
      "|   2018-02-27|                 26542|\n",
      "|   2018-02-28|                 26884|\n",
      "|   2018-03-01|                 27719|\n",
      "|   2018-03-02|                 27278|\n",
      "+-------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnewFrame\u001b[39m: \u001b[32mDataFrame\u001b[39m = [country_code: string, device_id: string ... 13 more fields]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//2.Calculate daily active users trend over month\n",
    "val newFrame = frame.withColumn(\"Date_of_event\",to_date(col(\"timestamp\"),\"yyyy-MM-dd\"))\n",
    "newFrame.groupBy(\"Date_of_event\").agg(count(\"device_id\").alias(\"Number of active users\")).sort(\"Date_of_event\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+--------+\n",
      "|Week_of_month|Day_of_week|Activity|\n",
      "+-------------+-----------+--------+\n",
      "|            1|          6|   26682|\n",
      "|            1|          4|   27719|\n",
      "|            1|          5|   52733|\n",
      "|            2|          7|   28148|\n",
      "|            2|          4|   25137|\n",
      "|            2|          5|   25859|\n",
      "|            2|          6|   26963|\n",
      "|            2|          3|   24123|\n",
      "|            2|          2|   25070|\n",
      "|            2|          1|   25876|\n",
      "|            3|          5|   26747|\n",
      "|            3|          3|   26451|\n",
      "|            3|          1|   30262|\n",
      "|            3|          2|   26881|\n",
      "|            3|          6|   26456|\n",
      "|            3|          4|   25735|\n",
      "|            3|          7|   28552|\n",
      "|            4|          5|   27600|\n",
      "|            4|          2|   25734|\n",
      "|            4|          6|   28744|\n",
      "|            4|          4|   26768|\n",
      "|            4|          1|   25989|\n",
      "|            4|          7|   27925|\n",
      "|            4|          3|   26540|\n",
      "|            5|          3|   26884|\n",
      "|            5|          7|   29186|\n",
      "|            5|          1|   26895|\n",
      "|            5|          2|   26542|\n",
      "+-------------+-----------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mx\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m7\u001b[39m)\n",
       "\u001b[36mweekdayFrame\u001b[39m: \u001b[32mDataFrame\u001b[39m = [country_code: string, device_id: string ... 14 more fields]\n",
       "\u001b[36mgrouped_Weekday\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Week_of_month: string, Day_of_week: string ... 1 more field]\n",
       "\u001b[36mfiltered_Weekday\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Week_of_month: string, Day_of_week: string ... 1 more field]\n",
       "\u001b[36msorted_Weekday\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Week_of_month: string, Day_of_week: string ... 1 more field]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 3. Calculate weekly seasonality\n",
    "var x = List(1,2,3,4,5,6,7)\n",
    "var weekdayFrame = frame.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\")))\n",
    "  .withColumn(\"Day_of_week\", date_format(col(\"timestamp\"), \"u\"))\n",
    "  .withColumn(\"Week_of_month\", date_format(col(\"timestamp\"), \"W\"))\n",
    "\n",
    "var grouped_Weekday = weekdayFrame.cube(\"Week_of_month\", \"Day_of_week\").agg(count(\"device_id\").alias(\"Activity\"))\n",
    "var filtered_Weekday = grouped_Weekday.filter(col(\"Week_of_month\").isin(x:_*)).filter(col(\"Day_of_week\").isin(x:_*))\n",
    "var sorted_Weekday = filtered_Weekday.sort(\"Day_of_week\").sort(\"Week_of_month\")\n",
    "\n",
    "sorted_Weekday.show(50)\n",
    "// As timestamp is from 02-02-2018 to 02-03-2018  2 fridays of first week are \n",
    "// included which brought to activity to be doubled\n",
    "// Also I could not sort teh Day_of_wekk column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+\n",
      "|   event_type|Number of active users|\n",
      "+-------------+----------------------+\n",
      "|   photo_open|                   609|\n",
      "|   photo_like|                    91|\n",
      "|photo_comment|                     6|\n",
      "+-------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mx\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m\"photo_like\"\u001b[39m, \u001b[32m\"photo_open\"\u001b[39m, \u001b[32m\"photo_comment\"\u001b[39m)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/* Social Users description*/\n",
    "\n",
    "var x = List[String](\"photo_like\",\"photo_open\",\"photo_comment\")\n",
    "frame.groupBy(\"event_type\").agg(count(\"device_id\").alias(\"Number of active users\"))\n",
    ".sort(desc(\"Number of active users\")).filter(col(\"event_type\").isin(x:_*)).show()\n",
    "\n",
    "// No comment at this moment :) just assuming that Social users are not greater than 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.11)",
   "language": "scala",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
